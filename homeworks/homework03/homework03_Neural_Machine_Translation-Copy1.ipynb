{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework №3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Machine Translation in the wild\n",
    "In the third homework you are supposed to get the best translation you can for the EN-RU translation task.\n",
    "\n",
    "Basic approach using RNNs as encoder and decoder is implemented for you. \n",
    "\n",
    "Your ultimate task is to use the techniques we've covered, e.g.\n",
    "\n",
    "* Optimization enhancements (e.g. learning rate decay)\n",
    "\n",
    "* CNN encoder (with or without positional encoding)\n",
    "\n",
    "* attention/self-attention mechanism\n",
    "\n",
    "* pretraining the language model\n",
    "\n",
    "* [Byte Pair Encoding](https://github.com/rsennrich/subword-nmt)\n",
    "\n",
    "* or just fine-tunning BERT ;)\n",
    "\n",
    "to improve the translation quality. \n",
    "\n",
    "__Please use at least three different approaches/models and compare them (translation quality/complexity/training and evaluation time).__\n",
    "\n",
    "Write down some summary on your experiments and illustrate it with convergence plots/metrics and your thoughts. Just like you would approach a real problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might need to install the libraries below. Do it in the desired environment\n",
    "# if you are working locally.\n",
    "\n",
    "#! pip  install subword-nmt\n",
    "#! pip install nltk\n",
    "#! pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks to YSDA NLP course team for the data\n",
    "# (who thanks tilda and deephack teams for the data in their turn)\n",
    "\n",
    "import os\n",
    "path_do_data = '../../datasets/Machine_translation_EN_RU/data.txt'\n",
    "if not os.path.exists(path_do_data):\n",
    "    print(\"Dataset not found locally. Downloading from github.\")\n",
    "    !wget https://raw.githubusercontent.com/neychev/made_nlp_course/master/datasets/Machine_translation_EN_RU/data.txt -nc\n",
    "    path_do_data = './data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n",
    "from torchtext.datasets import TranslationDataset, Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from subword_nmt.learn_bpe import learn_bpe\n",
    "from subword_nmt.apply_bpe import BPE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main part\n",
    "__Here comes the preprocessing. Do not hesitate to use BPE or more complex preprocessing ;)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rd\n",
    "rd.seed(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_W = WordPunctTokenizer()\n",
    "def tokenize(x, tokenizer=tokenizer_W):\n",
    "    return tokenizer.tokenize(x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize=tokenize,\n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(tokenize=tokenize,\n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True)\n",
    "\n",
    "dataset = torchtext.data.TabularDataset(\n",
    "    path=path_do_data,\n",
    "    format='tsv',\n",
    "    fields=[('trg', TRG), ('src', SRC)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = dataset.split(split_ratio=[0.8, 0.15, 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 40000\n",
      "Number of validation examples: 2500\n",
      "Number of testing examples: 7500\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 3)\n",
    "TRG.build_vocab(train_data, min_freq = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (ru) vocabulary: 9220\n",
      "Unique tokens in target (en) vocabulary: 6677\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in source (ru) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are tokens from original (RU) corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " 'rooms',\n",
       " 'тренажерным',\n",
       " 'горнолыжным',\n",
       " 'чиангмая',\n",
       " 'э',\n",
       " 'stuttgart',\n",
       " 'шарлотт',\n",
       " 'замков',\n",
       " 'туалета']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC.vocab.itos[::1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And from target (EN) corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', 'sites', 'cove', 'compact', 'mobility', 'sweets', 'matsumoto']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRG.vocab.itos[::1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is example from train dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trg': ['the', 'villa', 'features', 'multiple', 'car', 'parking', 'and', 'is', '600', 'metres', 'away', 'from', 'vale', 'de', 'centianes', 'beach', '.'], 'src': ['кроме', 'того', ',', 'к', 'услугам', 'гостей', 'парковка', 'на', 'несколько', 'автомобилей', ',', 'а', 'расстояние', 'до', 'пляжа', 'вале', '-', 'де', '-', 'сентианес', 'составляет', '600', 'метров', '.']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the length distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length distribution in Train data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_length = map(len, [vars(x)['src'] for x in train_data.examples])\n",
    "trg_length = map(len, [vars(x)['trg'] for x in train_data.examples])\n",
    "\n",
    "print('Length distribution in Train data')\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"source length\")\n",
    "plt.hist(list(src_length), bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"translation length\")\n",
    "plt.hist(list(trg_length), bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length distribution in Test data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_length = map(len, [vars(x)['src'] for x in test_data.examples])\n",
    "trg_length = map(len, [vars(x)['trg'] for x in test_data.examples])\n",
    "\n",
    "print('Length distribution in Test data')\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"source length\")\n",
    "plt.hist(list(src_length), bins=20);\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"translation length\")\n",
    "plt.hist(list(trg_length), bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model side\n",
    "__Here comes simple pipeline of NMT model learning. It almost copies the week03 practice__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _len_sort_key(x):\n",
    "    return len(x.src)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device,\n",
    "    sort_key=_len_sort_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 128]\n",
      "\t[.trg]:[torch.LongTensor of size 49x128]\n",
      "\t[.src]:[torch.LongTensor of size 55x128]\n",
      "torch.Size([55, 128]) torch.Size([49, 128])\n"
     ]
    }
   ],
   "source": [
    "for x in train_iterator:\n",
    "    break\n",
    "print(x)\n",
    "print(x.src.shape, x.trg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! install pytorch-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_network\n",
    "Encoder = my_network.Encoder\n",
    "Decoder = my_network.Decoder\n",
    "Seq2Seq = my_network.Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "# dont forget to put the model to the right device\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(9220, 256)\n",
       "    (lstm): LSTM(256, 512, num_layers=2, dropout=0.5, bidirectional=True)\n",
       "    (dropout): Dropout(p=0.5)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(6677, 256)\n",
       "    (lstm): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (attn): Attention(\n",
       "      (linear_in): Linear(in_features=512, out_features=512, bias=False)\n",
       "      (linear_out): Linear(in_features=1024, out_features=512, bias=False)\n",
       "      (softmax): Softmax()\n",
       "      (tanh): Tanh()\n",
       "    )\n",
       "    (out): Linear(in_features=1024, out_features=6677, bias=True)\n",
       "    (dropout): Dropout(p=0.5)\n",
       "  )\n",
       "  (linear_lt): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (linear_st): Linear(in_features=1024, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    # <YOUR CODE HERE>\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 25,881,365 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = TRG.vocab.stoi['<pad>']\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip, train_history=None, valid_history=None):\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    history = []\n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        #trg = [trg sent len, batch size]\n",
    "        #output = [trg sent len, batch size, output dim]\n",
    "        \n",
    "        output = output[1:].view(-1, output.shape[-1])\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        #trg = [(trg sent len - 1) * batch size]\n",
    "        #output = [(trg sent len - 1) * batch size, output dim]\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Let's clip the gradient\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        history.append(loss.cpu().data.numpy())\n",
    "        if (i+1)%10==0:\n",
    "            fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 8))\n",
    "\n",
    "            clear_output(True)\n",
    "            ax[0].plot(history, label='train loss')\n",
    "            ax[0].set_xlabel('Batch')\n",
    "            ax[0].set_title('Train loss')\n",
    "            if train_history is not None:\n",
    "                ax[1].plot(train_history, label='general train history')\n",
    "                ax[1].set_xlabel('Epoch')\n",
    "            if valid_history is not None:\n",
    "                ax[1].plot(valid_history, label='general valid history')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            #trg = [trg sent len, batch size]\n",
    "            #output = [trg sent len, batch size, output dim]\n",
    "\n",
    "            output = output[1:].view(-1, output.shape[-1])\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            #trg = [(trg sent len - 1) * batch size]\n",
    "            #output = [(trg sent len - 1) * batch size, output dim]\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = []\n",
    "valid_history = []\n",
    "\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-888f7ba0850f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-98cbc618a52c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip, train_history, valid_history)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Let's clip the gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP, train_history, valid_history)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    train_history.append(train_loss)\n",
    "    valid_history.append(valid_loss)\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Let's take a look at our network quality__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "del utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import imp\n",
    "imp.reload(utils)\n",
    "generate_translation = utils.generate_translation\n",
    "remove_tech_tokens = utils.remove_tech_tokens\n",
    "get_text = utils.get_text\n",
    "flatten = utils.flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(test_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: there is a 24 - hour front desk at the property .\n",
      "Generated: the property offers a 24 - hour front desk . .\n",
      "\n",
      "Original: this property also features free wifi .\n",
      "Generated: free wifi access . . . .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx in [1,2]:\n",
    "    src = batch.src[:, idx:idx+1]\n",
    "    trg = batch.trg[:, idx:idx+1]\n",
    "    generate_translation(src, trg, model, TRG.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "#     \"\"\" Estimates corpora-level BLEU score of model's translations given inp and reference out \"\"\"\n",
    "#     translations, _ = model.translate_lines(inp_lines, **flags)\n",
    "#     # Note: if you experience out-of-memory error, split input lines into batches and translate separately\n",
    "#     return corpus_bleu([[ref] for ref in out_lines], translations) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "59it [00:03, 18.87it/s]\n"
     ]
    }
   ],
   "source": [
    "original_text = []\n",
    "generated_text = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "    for i, batch in tqdm.tqdm(enumerate(test_iterator)):\n",
    "\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "\n",
    "        output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "        #trg = [trg sent len, batch size]\n",
    "        #output = [trg sent len, batch size, output dim]\n",
    "\n",
    "        output = output.argmax(dim=-1)\n",
    "        \n",
    "        original_text.extend([get_text(x, TRG.vocab) for x in trg.cpu().numpy().T])\n",
    "        generated_text.extend([get_text(x, TRG.vocab) for x in output[1:].detach().cpu().numpy().T])\n",
    "\n",
    "# original_text = flatten(original_text)\n",
    "# generated_text = flatten(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.139920232081806"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_bleu([[text] for text in original_text], generated_text) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline solution BLEU score is quite low. Try to achieve at least __18__ BLEU on the test set. \n",
    "The checkpoints are:\n",
    "\n",
    "* __18__ - minimal score to submit the homework, 30% of points\n",
    "\n",
    "* __20__ - good score, 70% of points\n",
    "\n",
    "* __25__ - excellent score, 100% of points"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "homework.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
